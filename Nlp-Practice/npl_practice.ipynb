{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16733d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joy': 0, 'fear': 1, 'anger': 2, 'sadness': 3}\n",
      "Vocabulary size: 9060\n",
      "First 20 words: ['aaaaarrrrgghhh' 'aameen' 'aamnaa' 'aaron' 'aaronrodgers' 'aarp'\n",
      " 'aasadeq' 'abbeygray' 'abc' 'abdophoto' 'abhors' 'ability' 'able' 'abood'\n",
      " 'aboutsin' 'abroad' 'absence' 'absolute' 'absolutely' 'absurd']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv('emotion-labels-test.csv')\n",
    "\n",
    "vectorize = CountVectorizer()\n",
    "\n",
    "#text to conver number \n",
    "unique_label = df['label'].unique()\n",
    "\n",
    "dec = {}\n",
    "i = 0\n",
    "for b in unique_label:\n",
    "    dec[b] = i\n",
    "    i+=1\n",
    "df['label'] = df['label'].map(dec)\n",
    "print(dec)\n",
    "\n",
    "#lowercase\n",
    "df['text'] = df['text'].apply(lambda x : x.lower())\n",
    "\n",
    "# remove number\n",
    "def remove_num(txt):\n",
    "    num = \"\"\n",
    "    for i in txt:\n",
    "        if not i.isdigit():\n",
    "            num +=i\n",
    "    return num\n",
    "\n",
    "df['text'] = df['text'].apply(remove_num)\n",
    "\n",
    "# remove symbole\n",
    "def remove_sym(txt):\n",
    "    return txt.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "df['text'] = df['text'].apply(remove_sym)\n",
    "\n",
    "#remove stopwords\n",
    "stop_word = set(stopwords.words('english'))\n",
    "\n",
    "def remove(txt):\n",
    "    cleane = [] # empty list \n",
    "    word = word_tokenize(txt)\n",
    "\n",
    "    for i in word:\n",
    "        if not i in stop_word:\n",
    "            cleane.append(i)\n",
    "            # print(cleane) \n",
    "    return ' '.join(cleane)\n",
    "\n",
    "df['text'] = df['text'].apply(remove)\n",
    "\n",
    "# vectorization\n",
    "document = df['text']\n",
    "x = vectorize.fit_transform(document)\n",
    "\n",
    "# print(f'Vocablary {vectorize.get_feature_names_out()}')\n",
    "print(f\"Vocabulary size: {len(vectorize.get_feature_names_out())}\")\n",
    "print(f\"First 20 words: {vectorize.get_feature_names_out()[:20]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
